{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import yaml\n",
    "import os\n",
    "import PIL\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_util (from object_detection.utils)\n",
    "# not available for tensorflow versions below 1.4\n",
    "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Utility functions for creating TFRecord data sets.\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def int64_feature(value):\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def int64_list_feature(value):\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def bytes_feature(value):\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def bytes_list_feature(value):\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "\n",
    "def float_list_feature(value):\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "\n",
    "def read_examples_list(path):\n",
    "  \"\"\"Read list of training or validation examples.\n",
    "\n",
    "  The file is assumed to contain a single example per line where the first\n",
    "  token in the line is an identifier that allows us to find the image and\n",
    "  annotation xml for that example.\n",
    "\n",
    "  For example, the line:\n",
    "  xyz 3\n",
    "  would allow us to find files xyz.jpg and xyz.xml (the 3 would be ignored).\n",
    "\n",
    "  Args:\n",
    "    path: absolute path to examples list file.\n",
    "\n",
    "  Returns:\n",
    "    list of example identifiers (strings).\n",
    "  \"\"\"\n",
    "  with tf.gfile.GFile(path) as fid:\n",
    "    lines = fid.readlines()\n",
    "  return [line.strip().split(' ')[0] for line in lines]\n",
    "\n",
    "\n",
    "def recursive_parse_xml_to_dict(xml):\n",
    "  \"\"\"Recursively parses XML contents to python dict.\n",
    "\n",
    "  We assume that `object` tags are the only ones that can appear\n",
    "  multiple times at the same level of a tree.\n",
    "\n",
    "  Args:\n",
    "    xml: xml tree obtained by parsing XML file contents using lxml.etree\n",
    "\n",
    "  Returns:\n",
    "    Python dictionary holding XML contents.\n",
    "  \"\"\"\n",
    "  if not xml:\n",
    "    return {xml.tag: xml.text}\n",
    "  result = {}\n",
    "  for child in xml:\n",
    "    child_result = recursive_parse_xml_to_dict(child)\n",
    "    if child.tag != 'object':\n",
    "      result[child.tag] = child_result[child.tag]\n",
    "    else:\n",
    "      if child.tag not in result:\n",
    "        result[child.tag] = []\n",
    "      result[child.tag].append(child_result[child.tag])\n",
    "  return {xml.tag: result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label dictionary for training and testing data\n",
    "LABEL_DICT =  {\n",
    "    \"Green\" : 1,\n",
    "    \"Red\" : 2,\n",
    "    \"Yellow\" : 3,\n",
    "    \"off\" : 4,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directories:\n",
      "data/bosch_train\n",
      "data/sdce_sim\n",
      "data/sdce_real\n"
     ]
    }
   ],
   "source": [
    "# Label files for datasets\n",
    "bosch_train_yaml = 'data/bosch_train/train.yaml'               # 5093 labels for .png images\n",
    "sim_train_yaml   = 'data/sdce_sim/sim_data_annotations.yaml'   # 277 labels for .jpg images\n",
    "real_train_yaml  = 'data/sdce_real/real_data_annotations.yaml' # 159 labels .jpg images\n",
    "\n",
    "# Directories for datasets\n",
    "bosch_train_dir  = os.path.dirname(bosch_train_yaml)\n",
    "sim_train_dir    = os.path.dirname(sim_train_yaml)\n",
    "real_train_dir   = os.path.dirname(real_train_yaml)\n",
    "\n",
    "print(\"Dataset directories:\")\n",
    "print(bosch_train_dir)\n",
    "print(sim_train_dir)\n",
    "print(real_train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load label index information from yaml files\n",
    "bosch_index = yaml.load(open(bosch_train_yaml, 'rb').read())\n",
    "sim_index   = yaml.load(open(sim_train_yaml, 'rb').read())\n",
    "real_index  = yaml.load(open(real_train_yaml, 'rb').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to determine whether bosch box labels are \"good\" (usable)\n",
    "def good_bosch_record(boxes):\n",
    "    \n",
    "    # bad if no boxes included\n",
    "    if not boxes:\n",
    "        return False\n",
    "    \n",
    "    # bad if one of the boxes too small or false box label in one of the boxes\n",
    "    for box in boxes:\n",
    "        width  = box['x_max'] - box['x_min']\n",
    "        height = box['y_max'] - box['y_min']    \n",
    "        if height < 10 or width < 5 or box['label'] not in LABEL_DICT:\n",
    "            return False\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bosch records: 1195/5093 satisfy our condition\n"
     ]
    }
   ],
   "source": [
    "# Select appropriate samples from large Bosch dataset\n",
    "numel_good = 0\n",
    "for record in bosch_index:\n",
    "    if good_bosch_record(record['boxes']):\n",
    "        numel_good += 1\n",
    "        \n",
    "print(\"bosch records: {}/{} satisfy our condition\".format(numel_good, len(bosch_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the bosch label index to the \"good\" records, convert .png images to .jpg and move samples to jpg folder \n",
    "bosch_reduced_index = [record.copy() for record in bosch_index if good_bosch_record(record['boxes'])]\n",
    "# Previous subdirectory\n",
    "sub_prev = '/' + 'rgb' + '/'\n",
    "# Target subdirectory\n",
    "sub_jpg  = '/' + 'jpg' + '/'\n",
    "\n",
    "# Convert Bosch record images in folder rgb and save to folder jpg\n",
    "i_record = 0\n",
    "for record in bosch_reduced_index:\n",
    "    new_relative_path = os.path.splitext(record['path'])[0] + '.jpg'\n",
    "    new_relative_path = new_relative_path.replace(sub_prev, sub_jpg, 1)    \n",
    "    source_path = os.path.normpath(os.path.join(bosch_train_dir, record['path']))\n",
    "    target_path = os.path.normpath(os.path.join(bosch_train_dir, new_relative_path))\n",
    "    \n",
    "    if not os.path.exists(target_path):\n",
    "        # export jpg file\n",
    "        new_dir = os.path.dirname(target_path)\n",
    "        if not os.path.exists(new_dir):\n",
    "            os.makedirs(new_dir)\n",
    "    \n",
    "        img = PIL.Image.open(source_path)\n",
    "        # img = img.resize((1067, 600), PIL.Image.ANTIALIAS)\n",
    "        img.save(target_path)\n",
    "        \n",
    "    record['path'] = new_relative_path\n",
    "    bosch_reduced_index[i_record]['path'] = new_relative_path # added to additionally adapt the reduced index saved as a new yaml dump afterwards\n",
    "    i_record += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save reduced bosch index as yaml\n",
    "bosch_good_yaml = os.path.join(bosch_train_dir, 'train_good.yaml')\n",
    "with open(bosch_good_yaml, 'w') as fid:\n",
    "    yaml.dump(bosch_reduced_index, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data labels to bosch format \n",
    "def get_bosch_record_with_relative_path(record, base):\n",
    "    if 'filename' in record:\n",
    "        # this is a yaml record from the sdce dataset with labels to be converted to Bosch format\n",
    "        boxes = [{'label': a['class'], \n",
    "                  'x_min': a['xmin'],\n",
    "                  'x_max': a['xmin'] + a['x_width'],\n",
    "                  'y_min': a['ymin'],\n",
    "                  'y_max': a['ymin'] + a['y_height']} for a in record['annotations']]\n",
    "        \n",
    "        return {'boxes': boxes,\n",
    "                'path': os.path.normpath(os.path.join(base, record['filename']))}\n",
    "    \n",
    "    else:\n",
    "        # this is a yaml record from the Bosch dataset with labels in Bosch format\n",
    "        ret = record.copy()\n",
    "        ret['path'] = os.path.normpath(os.path.join(base, record['path']))\n",
    "        \n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated sdce dataset (277 labels for .jpg images)\n",
    "sim_set   = [get_bosch_record_with_relative_path(r, sim_train_dir) for r in sim_index]\n",
    "\n",
    "# Real sdce dataset (159 labels .jpg images)\n",
    "real_set  = [get_bosch_record_with_relative_path(r, real_train_dir) for r in real_index]\n",
    "\n",
    "# Bosch dataset (5093 labels for .png images converted to .jpg)\n",
    "bosch_set = [get_bosch_record_with_relative_path(r, bosch_train_dir) for r in bosch_reduced_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset visualization function\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def plot_dataset(dataset, dataset_name = 'dataset'):\n",
    "\n",
    "    print(\"Dataset {} ({} samples)\\n\".format(dataset_name, np.size(dataset)))\n",
    "    for i_img in range(len(dataset)):\n",
    "        print(\"{}[{}]:\\n{}\".format(dataset_name, i_img, dataset[i_img])) #print(\"dataset[{}]:\\n{}\".format(i_img, dataset[i_img]))\n",
    "        img_path = dataset[i_img]['path'] #bosch_train_dir + bosch_reduced_index[i_img]['path'][1:]\n",
    "        image    = plt.imread(img_path)    \n",
    "\n",
    "        fig,ax = plt.subplots(1)\n",
    "        fig.set_size_inches(12, 6)\n",
    "        ax.imshow(image)\n",
    "        for i_rect in range (len(dataset[i_img]['boxes'])):\n",
    "            x_min = dataset[i_img]['boxes'][i_rect]['x_min']\n",
    "            y_min = dataset[i_img]['boxes'][i_rect]['y_min']\n",
    "            dx    = dataset[i_img]['boxes'][i_rect]['x_max'] - dataset[i_img]['boxes'][i_rect]['x_min']\n",
    "            dy    = dataset[i_img]['boxes'][i_rect]['y_max'] - dataset[i_img]['boxes'][i_rect]['y_min']\n",
    "            rect_color = 'blue'\n",
    "            if dataset[i_img]['boxes'][i_rect]['label'] == 'Red':\n",
    "                rect_color = 'red'\n",
    "            elif dataset[i_img]['boxes'][i_rect]['label'] == 'Yellow':\n",
    "                rect_color = 'yellow'\n",
    "            elif dataset[i_img]['boxes'][i_rect]['label'] == 'Green':\n",
    "                rect_color = 'green'        \n",
    "            rect = patches.Rectangle((x_min,y_min),dx,dy,linewidth=3,edgecolor=rect_color,facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dataset visualization (uncomment relevant line, many plots!)\n",
    "#plot_dataset(sim_set  , 'sim_set')\n",
    "#plot_dataset(real_set , 'real_set')\n",
    "#plot_dataset(bosch_set, 'bosch_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create shuffled training and test sets\n",
    "test_size    = 0.2 # proportion of testing samples in relation to whole dataset (rest: training)\n",
    "random_state = 42 # guaranteed to have the same random sequence by using the same seed number\n",
    "\n",
    "# Simulated sdce dataset\n",
    "sim_train_set, sim_test_set = train_test_split(\n",
    "    sim_set, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# Real sdce dataset\n",
    "real_train_set, real_test_set = train_test_split(\n",
    "    real_set, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# Bosch dataset\n",
    "bosch_train_set, bosch_test_set = train_test_split(\n",
    "    bosch_set, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# Global train and test set consisting of Simulated sdce dataset, Real sdce dataset and Bosch dataset\n",
    "train_set = shuffle(sim_train_set + real_train_set + bosch_train_set, random_state=random_state)\n",
    "test_set  = shuffle(sim_test_set + real_test_set + bosch_test_set, random_state=random_state)\n",
    "\n",
    "# Simulation train and test set consisting of Simulated sdce dataset\n",
    "train_set_sim_res = shuffle(sim_train_set, random_state=random_state)\n",
    "test_set_sim_res  = shuffle(sim_test_set, random_state=random_state)\n",
    "\n",
    "# Real train and test set consisting of Real sdce dataset and Bosch dataset\n",
    "train_set_real_res = shuffle(real_train_set + bosch_train_set, random_state=random_state)\n",
    "test_set_real_res  = shuffle(real_test_set + bosch_test_set, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensorflow record files for training and testing\n",
    "def create_tf_record(record):\n",
    "    image_path = record['path']\n",
    "    \n",
    "    with tf.gfile.GFile(image_path, 'rb') as fid:\n",
    "        encoded_image = fid.read()\n",
    "    \n",
    "    img    = PIL.Image.open(image_path)\n",
    "    width  = img.size[0]\n",
    "    height = img.size[1]\n",
    "    \n",
    "    # relative boxes\n",
    "    x_min = [float(box['x_min']) / width  for box in record['boxes']]\n",
    "    x_max = [float(box['x_max']) / width  for box in record['boxes']]\n",
    "    y_min = [float(box['y_min']) / height for box in record['boxes']]\n",
    "    y_max = [float(box['y_max']) / height for box in record['boxes']]\n",
    "    \n",
    "    text_label = [box['label'].encode() for box in record['boxes']]\n",
    "    num_label = [int(LABEL_DICT[box['label']]) for box in record['boxes']]\n",
    "    \n",
    "    image_format = os.path.splitext(image_path)[1].encode()\n",
    "    image_path   = image_path.encode()\n",
    "    \n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': int64_feature(height),\n",
    "        'image/width': int64_feature(width),\n",
    "        'image/filename': bytes_feature(image_path),\n",
    "        'image/source_id': bytes_feature(image_path),\n",
    "        'image/encoded': bytes_feature(encoded_image),\n",
    "        'image/format': bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': float_list_feature(x_min),\n",
    "        'image/object/bbox/xmax': float_list_feature(x_max),\n",
    "        'image/object/bbox/ymin': float_list_feature(y_min),\n",
    "        'image/object/bbox/ymax': float_list_feature(y_max),\n",
    "        'image/object/class/text': bytes_list_feature(text_label),\n",
    "        'image/object/class/label': int64_list_feature(num_label),\n",
    "    }))\n",
    "\n",
    "    return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write training and testing records\n",
    "def record_writer(output_file, record_sets):\n",
    "    writer = tf.python_io.TFRecordWriter(output_file)\n",
    "    \n",
    "    for record in record_sets:\n",
    "        tf_example = create_tf_record(record)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "        \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create overall training and testing record\n",
    "record_writer('data/tl_srb_training.record', train_set)\n",
    "record_writer('data/tl_srb_testing.record', test_set)\n",
    "\n",
    "# Create training and testing record for simulation data\n",
    "record_writer('data/tl_sim_training.record', train_set_sim_res)\n",
    "record_writer('data/tl_sim_testing.record', test_set_sim_res)\n",
    "\n",
    "# Create training and testing record real data (sdce and Bosch)\n",
    "record_writer('data/tl_real_training.record', train_set_real_res)\n",
    "record_writer('data/tl_real_testing.record', test_set_real_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your model (done on server)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1_Capstone]",
   "language": "python",
   "name": "conda-env-carnd-term1_Capstone-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
